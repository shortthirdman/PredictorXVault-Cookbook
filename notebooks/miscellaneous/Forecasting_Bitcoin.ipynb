{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccedd084-7332-4297-905e-b023f541bf13",
   "metadata": {},
   "source": [
    "### [Forecasting Bitcoin Autocorrelation](https://pyquantlab.medium.com/forecasting-bitcoin-autocorrelation-with-74-directional-accuracy-using-lstms-59ba7395fd48)\n",
    "\n",
    "> 74% Directional Accuracy using LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebc9584-a846-455f-95f4-bc8d9f365b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas yfinance matplotlib\n",
    "!pip install -q scikit-learn \"tensorflow==2.18.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19359ef1-2f39-4c01-8f36-1d1c4f44696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96362da1-7ec5-4dda-af0b-4f69a11a5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2b103f-f3cf-46f9-8414-1713b1c06cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Feature Parameters\n",
    "ticker = 'BTC-USD'\n",
    "start_date = '2023-01-01'\n",
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "rolling_window = 30 # Window for calculating autocorrelation\n",
    "lag = 1             # Lag for autocorrelation (day-over-day)\n",
    "\n",
    "# Model Hyperparameters\n",
    "num_lags = 90       # How many past autocorrelation values to use as input\n",
    "train_test_split = 0.80 # 80% for training, 20% for testing\n",
    "num_neurons_in_hidden_layers = 128 # LSTM layer size\n",
    "num_epochs = 100    # Max training epochs\n",
    "batch_size = 20     # Samples per gradient update\n",
    "dropout_rate = 0.1  # Regularization rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db75844-79f2-4922-8a38-84262aabefec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching BTC-USD data from 2023-01-01 to 2025-04-29...\n",
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched successfully. Shape: (849,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fetching {ticker} data from {start_date} to {end_date}...\")\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "# Clean up potential multi-level columns from yfinance\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = data.columns.droplevel(1)\n",
    "data = data['Close'] # We only need closing prices\n",
    "data = data.dropna()\n",
    "print(f\"Data fetched successfully. Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761a9ac5-d104-44cd-8b82-c14a3ee3fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 30-day rolling autocorrelation (lag=1)...\n",
      "Rolling autocorrelation calculated. Shape: (820,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Calculating {rolling_window}-day rolling autocorrelation (lag={lag})...\")\n",
    "rolling_autocorr_series = data.rolling(\n",
    "    window=rolling_window\n",
    ").apply(lambda x: x.autocorr(lag=lag), raw=False) # Use pandas Series method\n",
    "\n",
    "rolling_autocorr = rolling_autocorr_series.dropna().values # Drop initial NaNs\n",
    "rolling_autocorr = np.reshape(rolling_autocorr, (-1)) # Ensure 1D shape\n",
    "print(f\"Rolling autocorrelation calculated. Shape: {rolling_autocorr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c926c1-494d-44df-aea1-f7f74d959fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: X_train=(584, 90), y_train=(584,), X_test=(146, 90), y_test=(146,)\n"
     ]
    }
   ],
   "source": [
    "def data_preprocessing(data_series, n_lags, train_split_ratio):\n",
    "    \"\"\"\n",
    "    Prepares time series data into lags for supervised learning and splits.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    # Create sequences: Use 'n_lags' points to predict the next point\n",
    "    for i in range(n_lags, len(data_series)):\n",
    "        X.append(data_series[i-n_lags:i])\n",
    "        y.append(data_series[i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    split_index = int(len(X) * train_split_ratio)\n",
    "    x_train = X[:split_index]\n",
    "    y_train = y[:split_index]\n",
    "    x_test = X[split_index:]\n",
    "    y_test = y[split_index:]\n",
    "    print(f\"Data shapes: X_train={x_train.shape}, y_train={y_train.shape}, X_test={x_test.shape}, y_test={y_test.shape}\")\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Create the datasets\n",
    "x_train, y_train, x_test, y_test = data_preprocessing(\n",
    "    rolling_autocorr, num_lags, train_test_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833cda9e-a443-449d-9a29-fb0d82cae78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reshaped for LSTM: x_train=(584, 90, 1), x_test=(146, 90, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape Input for LSTM [samples, time steps, features]\n",
    "x_train = x_train.reshape((-1, num_lags, 1))\n",
    "x_test = x_test.reshape((-1, num_lags, 1))\n",
    "print(f\"Data reshaped for LSTM: x_train={x_train.shape}, x_test={x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383464da-5fb3-421f-a5b4-3409de9dade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LSTM model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,560\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,201</span> (262.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,201\u001b[0m (262.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,945</span> (261.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,945\u001b[0m (261.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Building LSTM model...\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=num_neurons_in_hidden_layers, input_shape=(num_lags, 1)))\n",
    "model.add(BatchNormalization()) # Regularization / Stability\n",
    "model.add(Dropout(dropout_rate)) # Regularization\n",
    "model.add(Dense(units=1))       # Output layer\n",
    "\n",
    "# Compile: Define loss function and optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary() # Display model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e11db5d-2aca-40dc-ad39-a6c84f11d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - loss: 0.5166\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0782\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0236\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0299\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0274\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0181\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0171\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0199\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0195\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0166\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0165\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0182\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0163\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0181\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0192\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0188\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0162\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0185\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0171\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0157\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0160\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0157\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0164\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0160\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0175\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0168\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0155\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0159\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0172\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0147\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0170\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0162\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0159\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0153\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0156\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0159\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0163\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0154\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0156\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0163\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0158\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0166\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0162\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0161\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0150\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Training finished.\n",
      "Early stopping triggered at epoch 45\n"
     ]
    }
   ],
   "source": [
    "# Early stopping implementation\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=15,\n",
    "                             restore_best_weights=True, verbose=1)\n",
    "\n",
    "print(\"Training model...\")\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1,\n",
    "                    shuffle=False) # Keep temporal order if needed\n",
    "print(\"Training finished.\")\n",
    "if early_stopping.stopped_epoch > 0:\n",
    "    print(f\"Early stopping triggered at epoch {early_stopping.stopped_epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e7caf2-8da4-41f0-9ecd-529e4144426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting...\")\n",
    "y_predicted_train = model.predict(x_train).flatten()\n",
    "y_predicted_test = model.predict(x_test).flatten()\n",
    "\n",
    "# Prepare actual values (flatten)\n",
    "y_train_flat = y_train.flatten()\n",
    "y_test_flat = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6e0a1a-2b51-4d87-a17c-a80eba8e3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_directional_accuracy(actual, predicted):\n",
    "    actual = np.asarray(actual)\n",
    "    predicted = np.asarray(predicted)\n",
    "\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"Actual and predicted arrays must be of the same length.\")\n",
    "    if len(actual) < 2:\n",
    "        raise ValueError(\"Need at least two points to compute directional accuracy.\")\n",
    "\n",
    "    # Compute daily changes\n",
    "    actual_diff = np.diff(actual)\n",
    "    predicted_diff = np.diff(predicted)\n",
    "\n",
    "    # Calculate direction: sign of the difference (+1, -1, or 0)\n",
    "    actual_direction = np.sign(actual_diff)\n",
    "    predicted_direction = np.sign(predicted_diff)\n",
    "\n",
    "    # Count how many times the directions matched\n",
    "    correct_direction = actual_direction == predicted_direction\n",
    "    directional_accuracy = np.mean(correct_direction) * 100  # as a percentage\n",
    "\n",
    "    return directional_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1072ddbc-9d0d-4aef-8fb9-d293c3c143d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating performance...\n",
      "\n",
      "--- Results ---\n",
      "RMSE (Train): 0.20620331707603212\n",
      "RMSE (Test): 0.19150318450092627\n",
      "Directional Accuracy (Train): 71.35506003430532\n",
      "Directional Accuracy (Test): 73.79310344827587\n",
      "Minimum length of train dataset: 584\n",
      "Minimum length of test dataset: 146\n",
      "Correlation In-Sample Predicted/Train: 0.9686713968669628\n",
      "Correlation Out-of-Sample Predicted/Test: 0.9594252771398107\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating performance...\")\n",
    "# Calculate Metrics\n",
    "rmse_train = sqrt(mean_squared_error(y_train_flat, y_predicted_train))\n",
    "rmse_test = sqrt(mean_squared_error(y_test_flat, y_predicted_test))\n",
    "\n",
    "# (Assuming calculate_directional_accuracy function is defined as above)\n",
    "accuracy_train = calculate_directional_accuracy(y_train_flat, y_predicted_train)\n",
    "accuracy_test = calculate_directional_accuracy(y_test_flat, y_predicted_test)\n",
    "\n",
    "min_len_train = min(len(y_train_flat), len(y_predicted_train))\n",
    "min_len_test = min(len(y_test_flat), len(y_predicted_test))\n",
    "correlation_train = np.corrcoef(y_train_flat[:min_len_train], y_predicted_train[:min_len_train])[0, 1]\n",
    "correlation_test = np.corrcoef(y_test_flat[:min_len_test], y_predicted_test[:min_len_test])[0, 1]\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"RMSE (Train): {rmse_train}\")\n",
    "print(f\"RMSE (Test): {rmse_test}\")\n",
    "\n",
    "print(f\"Directional Accuracy (Train): {accuracy_train}\")\n",
    "print(f\"Directional Accuracy (Test): {accuracy_test}\")\n",
    "\n",
    "print(f\"Minimum length of train dataset: {min_len_train}\")\n",
    "print(f\"Minimum length of test dataset: {min_len_test}\")\n",
    "\n",
    "print(f\"Correlation In-Sample Predicted/Train: {correlation_train}\")\n",
    "print(f\"Correlation Out-of-Sample Predicted/Test: {correlation_test}\")\n",
    "print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70f702-de13-4eb7-a00d-43002bf656b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plotting results...\")\n",
    "# (Assuming plot_train_test_values function is defined as above)\n",
    "plot_train_test_values(n_train_plot=300, n_test_plot=len(y_test_flat),\n",
    "                       y_train=y_train_flat,\n",
    "                       y_test=y_test_flat,\n",
    "                       y_predicted=y_predicted_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
