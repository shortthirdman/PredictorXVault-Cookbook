{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39023043-18db-4d47-bbca-5776472ed6c2",
   "metadata": {},
   "source": [
    "## [K-Nearest Neighbor Regressor](https://medium.com/data-science/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889)\n",
    "\n",
    "> Finding the neighbors FAST with KD Trees and Ball Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7e051-c7d9-4775-a6c6-a2d28385bfed",
   "metadata": {},
   "source": [
    "The Nearest Neighbor Regressor is a straightforward predictive model that estimates values by averaging the outcomes of nearby data points. This method builds on the idea that similar inputs likely yield similar outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b7a60-2907-4758-8ac5-984003bf1416",
   "metadata": {},
   "source": [
    "The **Nearest Neighbor Regressor** works similarly to its classifier counterpart, but instead of voting on a class, it averages the target values. Here's the basic process:\n",
    "\n",
    "- Calculate the distance between the new data point and all points in the training set.\n",
    "- Select the K nearest neighbors based on these distances.\n",
    "- Calculate the average of the target values of these K neighbors.\n",
    "- Assign this average as the predicted value for the new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1e88b7-fd67-4c50-9cb6-5eeada549f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3504d9-61f4-470f-b9e8-a6f3ac7554ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85d074-558e-4b81-9f8e-6ca133abab6d",
   "metadata": {},
   "source": [
    "#### KD Tree for KNN Regression\n",
    "\n",
    "KD Tree (K-Dimensional Tree) is a binary tree structure used for organizing points in a k-dimensional space. It’s particularly useful for tasks like nearest neighbor searches and range searches in multidimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04ab61-44b2-4b5c-8ba5-33d49d97d9d6",
   "metadata": {},
   "source": [
    "#### Ball Tree for KNN Regression\n",
    "\n",
    "Ball Tree is another space-partitioning data structure that organizes points in a series of nested hyperspheres. It’s particularly effective for high-dimensional data where KD Trees may become less efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653f30bf-3ace-4568-9779-7544e19ecd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.6698\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create dataset\n",
    "dataset_dict = {\n",
    "    'Outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain', 'sunny', 'overcast', 'rain', 'sunny', 'sunny', 'rain', 'overcast', 'rain', 'sunny', 'overcast', 'sunny', 'overcast', 'rain', 'overcast'],\n",
    "    'Temperature': [85.0, 80.0, 83.0, 70.0, 68.0, 65.0, 64.0, 72.0, 69.0, 75.0, 75.0, 72.0, 81.0, 71.0, 81.0, 74.0, 76.0, 78.0, 82.0, 67.0, 85.0, 73.0, 88.0, 77.0, 79.0, 80.0, 66.0, 84.0],\n",
    "    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n",
    "    'Wind': [False, True, False, False, False, True, True, False, False, False, True, True, False, True, True, False, False, True, False, True, True, False, True, False, False, True, False, False],\n",
    "    'Num_Players': [52, 39, 43, 37, 28, 19, 43, 47, 56, 33, 49, 23, 42, 13, 33, 29, 25, 51, 41, 14, 34, 29, 49, 36, 57, 21, 23, 41]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dataset_dict)\n",
    "\n",
    "# One-hot encode 'Outlook' column\n",
    "df = pd.get_dummies(df, columns=['Outlook'])\n",
    "\n",
    "# Convert 'Wind' column to binary\n",
    "df['Wind'] = df['Wind'].astype(int)\n",
    "\n",
    "# Split data into features and target, then into training and test sets\n",
    "X, y = df.drop(columns='Num_Players'), df['Num_Players']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = ['Temperature', 'Humidity']\n",
    "\n",
    "# Create a ColumnTransformer to scale only numerical columns\n",
    "ct = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), numerical_columns)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit the ColumnTransformer on the training data and transform both training and test data\n",
    "X_train_transformed = ct.fit_transform(X_train)\n",
    "X_test_transformed = ct.transform(X_test)\n",
    "\n",
    "# Convert the transformed data back to DataFrames\n",
    "feature_names = numerical_columns + [col for col in X_train.columns if col not in numerical_columns]\n",
    "X_train_scaled = pd.DataFrame(X_train_transformed, columns=feature_names, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_transformed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "# Initialize and train KNN Regressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, \n",
    "                          algorithm='kd_tree', #'ball_tree', 'brute'\n",
    "                          leaf_size=5) #default is 30\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print RMSE\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
